import os
import json
from typing import List
from datetime import datetime, date

import streamlit as st
from groq import Groq
from pinecone import Pinecone
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv

load_dotenv()

# ======================================================
# CONFIG
# ======================================================

INDEX_NAME = os.getenv("PINECONE_INDEX", "cv-alumno")
EMBED_MODEL = "sentence-transformers/all-MiniLM-L6-v2"


# ======================================================
# METADATA
# ======================================================

def calcular_edad(fecha_str: str) -> int:
    fecha = datetime.strptime(fecha_str, "%Y-%m-%d").date()
    hoy = date.today()
    return hoy.year - fecha.year - ((hoy.month, hoy.day) < (fecha.month, fecha.day))


@st.cache_resource
def load_metadata():
    with open("docs/metadata.json", "r", encoding="utf-8") as f:
        meta = json.load(f)

    if "fecha_nacimiento" in meta:
        meta["edad"] = calcular_edad(meta["fecha_nacimiento"])

    return meta


def metadata_to_text(metadata: dict) -> str:
    lines = ["INFORMACI√ìN FIJA DEL CV:"]
    for k, v in metadata.items():
        k_fmt = k.replace("_", " ").capitalize()
        if isinstance(v, list):
            v = ", ".join(str(x) for x in v)
        lines.append(f"- {k_fmt}: {v}")
    return "\n".join(lines)


# ======================================================
# CLIENTS
# ======================================================

@st.cache_resource
def get_pinecone():
    key = os.getenv("PINECONE_API_KEY")
    return Pinecone(api_key=key)


@st.cache_resource
def get_index():
    return get_pinecone().Index(INDEX_NAME)


@st.cache_resource
def get_embedder():
    model = SentenceTransformer(EMBED_MODEL)
    return model, model.get_sentence_embedding_dimension()


@st.cache_resource
def get_groq():
    return Groq(api_key=os.getenv("GROQ_API_KEY"))


# ======================================================
# RAG
# ======================================================

def embed(text: str) -> List[float]:
    model, _ = get_embedder()
    return model.encode(text).tolist()


def retrieve(question: str, top_k: int = 5):
    idx = get_index()
    res = idx.query(vector=embed(question), top_k=top_k, include_metadata=True)
    return [m["metadata"].get("texto", "") for m in res.get("matches", [])]


def build_prompt(question: str, chunks: List[str]) -> str:
    metadata = load_metadata()
    metadata_txt = metadata_to_text(metadata)
    email = metadata.get("email")

    chunks_txt = "\n\n---\n\n".join(chunks) if chunks else "No se recuper√≥ informaci√≥n relevante."

    return f"""
        Eres un asistente que responde preguntas sobre mi perfil profesional a cualquier persona que quiera saber m√°‚à´s de mi.
        Respond√© con un tono natural, profesional y claro. No copies texto literal del CV.

        REGLAS:
        1. La metadata tiene prioridad absoluta.
        2. Los chunks solo sirven para complementar, sin copiar.
        3. Si algo NO est√° ni en metadata ni en chunks, respond√© EXACTAMENTE:
        "No tengo esa informaci√≥n, pero pod√©s escribirme a {email} para cualquier consulta adicional."
        4. Est√° prohibido calcular edad bajo cualquier forma. Si aparece ‚Äúedad‚Äù en metadata, usala. Si no, dec√≠ que no est√° disponible.
        5. No expliques reglas ni describas c√≥mo funcion√°s.

        METADATA:
        {metadata_txt}

        CHUNKS:
        {chunks_txt}

        PREGUNTA:
        {question}
        """.strip()


def generate_answer(question: str):
    client = get_groq()
    chunks = retrieve(question)
    prompt = build_prompt(question, chunks)

    resp = client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[
            {"role": "system", "content": "Sos un asistente profesional."},
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,
        max_tokens=600,
    )

    return resp.choices[0].message.content.strip()


# ======================================================
# STATE
# ======================================================

def init_state():
    if "history" not in st.session_state:
        st.session_state.history = []

    if "input_key" not in st.session_state:
        st.session_state.input_key = 0

    if "submitted" not in st.session_state:
        st.session_state.submitted = None


def submit():
    st.session_state.submitted = st.session_state[f"user_input_{st.session_state.input_key}"]


# ======================================================
# UI
# ======================================================

def bump_input_key():
    """Incrementa el key del input para forzar su reseteo."""
    if "input_key" not in st.session_state:
        st.session_state.input_key = 0
    st.session_state.input_key += 1


def main():
    st.set_page_config(
        layout="centered",
        page_title="CV Assistant ‚Äî Abril Noguera",
        page_icon="üíº"
    )

    init_state()

    # ---------- CSS GLOBAL ----------
    st.markdown("""
    <style>
    body { background-color: #0f172a; }

    .chat-user {
        background:#334155; padding:14px 18px; border-radius:12px;
        margin-bottom:10px; text-align:right; border:1px solid #475569;
        color:#e2e8f0;
    }

    .chat-bot {
        background:#1e293b; padding:14px 18px; border-radius:12px;
        margin-bottom:10px; border:1px solid #334155;
        color:#e2e8f0;
    }

    .header-name { font-size: 32px; color:#e2e8f0; margin-bottom:0; }
    .header-sub { font-size: 18px; color:#38bdf8; margin-top:4px; }
    </style>
    """, unsafe_allow_html=True)

    # ---------- HEADER ----------
    st.markdown("<br>", unsafe_allow_html=True)

    col_foto, col_head = st.columns([1, 3])

    with col_foto:
        st.image("docs/foto.jpg", width=150, caption="", output_format="auto")

    with col_head:
        st.markdown("<h1 class='header-name'>Abril Noguera</h1>", unsafe_allow_html=True)
        st.markdown("<div class='header-sub'>Asistente de CV ‚Äî Preguntame lo que quieras</div>", unsafe_allow_html=True)
        st.markdown("<p style='color:#94a3b8; font-size:15px;'>Ideal para una pre-entrevista o una primera impresi√≥n profesional.</p>", unsafe_allow_html=True)

    st.markdown("---")

    # ---------- CHAT ----------
    for msg in st.session_state.history:
        if msg["role"] == "user":
            st.markdown(f"<div class='chat-user'>{msg['content']}</div>", unsafe_allow_html=True)
        else:
            st.markdown(f"<div class='chat-bot'>{msg['content']}</div>", unsafe_allow_html=True)

    # ---------- INPUT ----------
    col1, col2 = st.columns([4, 1])

    with col1:
        # El input ahora tiene key din√°mico ‚Üí se limpia correctamente
        st.text_input(
            "Pregunta:",
            key=f"user_input_{st.session_state.input_key}",
            placeholder="Escrib√≠ tu pregunta sobre mi experiencia...",
            label_visibility="collapsed",
            on_change=submit
        )

    with col2:
        sent = st.button("Enviar")
        if sent:
            st.session_state.submitted = st.session_state.get(f"user_input_{st.session_state.input_key}", "")

    # ---------- PROCESAR PREGUNTA ----------
    if st.session_state.submitted:
        pregunta = st.session_state.submitted
        st.session_state.submitted = ""

        with st.spinner("Analizando mi CV..."):
            answer = generate_answer(
                pregunta
            )

        # Guardar en historial
        st.session_state.history.append({"role": "user", "content": pregunta})
        st.session_state.history.append({"role": "assistant", "content": answer})

        # üî• Limpiar input de forma correcta
        bump_input_key()

        # üîÅ Rerender
        st.rerun()

    # ---------- FOOTER ----------
    st.markdown("<br><br>", unsafe_allow_html=True)
    st.markdown(
        "<div style='text-align:center; color:#64748b; font-size:13px;'>¬© 2025 ‚Äî Abril Noguera ¬∑ CV Assistant (RAG + LLM)</div>",
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()